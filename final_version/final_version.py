# -*- coding: utf-8 -*-
"""Final-version.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xx_kbWwZnuOuujLCxeagUAPA4jkMy9eY
"""

# !pip install -U -q PyDrive

# from pydrive.auth import GoogleAuth
# from pydrive.drive import GoogleDrive
# from google.colab import auth
# from oauth2client.client import GoogleCredentials

# # 1. Authenticate and create the PyDrive client.
# auth.authenticate_user()
# gauth = GoogleAuth()
# gauth.credentials = GoogleCredentials.get_application_default()
# drive = GoogleDrive(gauth)

# downloaded = drive.CreateFile({'id':'data_id'})
# downloaded.GetContentFile('X_small.npy')
# downloaded = drive.CreateFile({'id':'inception_weight_id'})
# downloaded.GetContentFile('inception_resnet_V2_weights.h5')
# downloaded = drive.CreateFile({'id':'test_image_id'})
# downloaded.GetContentFile('2.jpg')

from keras.models import Sequential
from keras.layers import UpSampling2D, InputLayer, Input
from keras.layers import Conv2D
from keras.optimizers import RMSprop
from keras.utils import np_utils
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
import keras
import numpy as np
import matplotlib.pyplot as plt
from keras.models import Model, load_model
from keras.models import model_from_json
from skimage.color import rgb2lab,lab2rgb,gray2rgb,rgb2gray
import cv2
from keras.applications.inception_resnet_v2 import InceptionResNetV2
from keras.applications.inception_resnet_v2 import preprocess_input
from keras.layers import RepeatVector,Reshape,concatenate
from skimage.transform import resize
import tensorflow as tf

train = np.load('X_small.npy')

inception_model = InceptionResNetV2(weights = None, include_top = True)
inception_model.load_weights('inception_resnet_V2_weights.h5')
inception_model.graph = tf.get_default_graph()

embed_input = Input(shape = (1000,))

#Encoder

encoder_input = Input(shape = (256, 256, 1))
encoder_output = Conv2D(64, (3,3), activation = 'relu', padding = 'same', strides = 2)(encoder_input)
encoder_output = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(encoder_output)
encoder_output = Conv2D(128, (3,3), activation = 'relu', padding = 'same', strides = 2)(encoder_output)
encoder_output = Conv2D(256, (3,3), activation = 'relu', padding = 'same')(encoder_output)
encoder_output = Conv2D(256, (3,3), activation = 'relu', padding = 'same', strides = 2)(encoder_output)
encoder_output = Conv2D(512, (3,3), activation = 'relu', padding = 'same')(encoder_output)
encoder_output = Conv2D(512, (3,3), activation = 'relu', padding = 'same')(encoder_output)
encoder_output = Conv2D(256, (3,3), activation = 'relu', padding = 'same')(encoder_output)


#Fusion

fusion_output = RepeatVector(32 * 32)(embed_input)
fusion_output = Reshape(([32,32,1000]))(fusion_output)
fusion_output = concatenate([encoder_output, fusion_output], axis = 3)
fusion_output = Conv2D(256, (1,1), activation = 'relu', padding = 'same')(fusion_output)


#Decoder
decoder_output = Conv2D(128, (3,3), activation = 'relu', padding = 'same')(fusion_output)
decoder_output = UpSampling2D((2,2))(decoder_output)
decoder_output = Conv2D(64, (3,3), activation = 'relu', padding = 'same')(decoder_output)
decoder_output = UpSampling2D((2,2))(decoder_output)
decoder_output = Conv2D(32, (3,3), activation = 'relu', padding = 'same')(decoder_output)
decoder_output = Conv2D(16, (3,3), activation = 'relu', padding = 'same')(decoder_output)
decoder_output = Conv2D(2, (3,3), activation = 'tanh', padding = 'same')(decoder_output)
decoder_output = UpSampling2D((2,2))(decoder_output)

#Model

model = Model(inputs = [encoder_input, embed_input], outputs = decoder_output)

#create_inception_embedding

def create_inception_embedding(grayscaled_rgb):
  grayscaled_rgb_resized = []
  for i in grayscaled_rgb:
    i = resize(i, (299,299,3), mode = 'constant')
    grayscaled_rgb_resized.append(i)
  
  grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)
  grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)
  with inception_model.graph.as_default():
    embed = inception_model.predict(grayscaled_rgb_resized)
  return embed

datagen = ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        rotation_range=20,
        horizontal_flip=True)

batch_size = 20
def image_a_b_gen(batch_size):
    for batch in datagen.flow(train, batch_size=batch_size):
        grayscaled_rgb = gray2rgb(rgb2gray(batch))
        embed = create_inception_embedding(grayscaled_rgb)
        lab_batch = rgb2lab(batch)
        X_batch = lab_batch[:,:,:,0]
        X_batch = X_batch.reshape(X_batch.shape+(1,))
        Y_batch = lab_batch[:,:,:,1:] / 128        
        yield ([X_batch , embed], Y_batch)


model_new.compile(optimizer='adam', loss='mse',metrics=['accuracy'])

def predict_img(img):
  grayscaled_rgb = gray2rgb(rgb2gray(img))
  grayscaled_rgb = resize(grayscaled_rgb, (299, 299, 3), mode = 'constant')
  grayscaled_rgb = np.array(grayscaled_rgb).reshape((1,299,299,3))
  grayscaled_rgb = preprocess_input(grayscaled_rgb)
  embed_color_input = inception_model.predict(grayscaled_rgb)
  X_train = rgb2lab(img)[:,:,0].reshape((1,256,256,1))
  return model_new.predict([X_train, embed_color_input], steps=1)


pred = predict_img(img)

cur = np.zeros((256, 256, 3))
cur[:,:,0] = rgb2lab(img)[:,:,0].reshape((256,256))
cur[:,:,1:] = pred.reshape((256,256,2)) * 128

canvas = lab2rgb(cur)

# imsave('my_image.png',color.lab2rgb(canvas))

# file = drive.CreateFile({'parents':[{u'id': 'folder_id'}]})
# file.SetContentFile('my_image.png')
# file.Upload()